{
  "nodes": [
    {
      "id": "chatNvidiaNIM_0",
      "position": {
        "x": 2075,
        "y": -825
      },
      "type": "customNode",
      "data": {
        "id": "chatNvidiaNIM_0",
        "label": "Chat NVIDIA NIM",
        "version": 1.1,
        "name": "chatNvidiaNIM",
        "type": "ChatNvidiaNIM",
        "baseClasses": [
          "ChatNvidiaNIM",
          "BaseChatOpenAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around NVIDIA NIM Inference API",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "nvidiaNIMApi"
            ],
            "optional": true,
            "id": "chatNvidiaNIM_0-input-credential-credential",
            "display": true
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "string",
            "placeholder": "microsoft/phi-3-mini-4k-instruct",
            "id": "chatNvidiaNIM_0-input-modelName-string",
            "display": true
          },
          {
            "label": "Base Path",
            "name": "basePath",
            "type": "string",
            "description": "Specify the URL of the deployed NIM Inference API",
            "placeholder": "https://integrate.api.nvidia.com/v1",
            "id": "chatNvidiaNIM_0-input-basePath-string",
            "display": true
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatNvidiaNIM_0-input-temperature-number",
            "display": true
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "additionalParams": true,
            "id": "chatNvidiaNIM_0-input-streaming-boolean",
            "display": true
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatNvidiaNIM_0-input-maxTokens-number",
            "display": true
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatNvidiaNIM_0-input-topP-number",
            "display": true
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatNvidiaNIM_0-input-frequencyPenalty-number",
            "display": true
          },
          {
            "label": "Presence Penalty",
            "name": "presencePenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatNvidiaNIM_0-input-presencePenalty-number",
            "display": true
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatNvidiaNIM_0-input-timeout-number",
            "display": true
          },
          {
            "label": "Base Options",
            "name": "baseOptions",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "chatNvidiaNIM_0-input-baseOptions-json",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatNvidiaNIM_0-input-cache-BaseCache",
            "display": true
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "meta/llama-4-maverick-17b-128e-instruct",
          "basePath": "https://integrate.api.nvidia.com/v1",
          "temperature": "0.8",
          "streaming": true,
          "maxTokens": "",
          "topP": "",
          "frequencyPenalty": "",
          "presencePenalty": "",
          "timeout": "",
          "baseOptions": ""
        },
        "outputAnchors": [
          {
            "id": "chatNvidiaNIM_0-output-chatNvidiaNIM-ChatNvidiaNIM|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatNvidiaNIM",
            "label": "ChatNvidiaNIM",
            "description": "Wrapper around NVIDIA NIM Inference API",
            "type": "ChatNvidiaNIM | BaseChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 726,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 2075,
        "y": -825
      }
    },
    {
      "id": "bufferMemory_0",
      "position": {
        "x": 2075,
        "y": 350
      },
      "type": "customNode",
      "data": {
        "id": "bufferMemory_0",
        "label": "Buffer Memory",
        "version": 2,
        "name": "bufferMemory",
        "type": "BufferMemory",
        "baseClasses": [
          "BufferMemory",
          "BaseChatMemory",
          "BaseMemory"
        ],
        "category": "Memory",
        "description": "Retrieve chat messages stored in database",
        "inputParams": [
          {
            "label": "Session Id",
            "name": "sessionId",
            "type": "string",
            "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.com/memory#ui-and-embedded-chat\">more</a>",
            "default": "",
            "additionalParams": true,
            "optional": true,
            "id": "bufferMemory_0-input-sessionId-string",
            "display": true
          },
          {
            "label": "Memory Key",
            "name": "memoryKey",
            "type": "string",
            "default": "chat_history",
            "additionalParams": true,
            "id": "bufferMemory_0-input-memoryKey-string",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "sessionId": "",
          "memoryKey": "chat_history"
        },
        "outputAnchors": [
          {
            "id": "bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory",
            "name": "bufferMemory",
            "label": "BufferMemory",
            "description": "Retrieve chat messages stored in database",
            "type": "BufferMemory | BaseChatMemory | BaseMemory"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 259,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 2075,
        "y": 350
      }
    },
    {
      "id": "pdfFile_0",
      "position": {
        "x": 1650,
        "y": -450
      },
      "type": "customNode",
      "data": {
        "id": "pdfFile_0",
        "label": "Pdf File",
        "version": 2,
        "name": "pdfFile",
        "type": "Document",
        "baseClasses": [
          "Document"
        ],
        "category": "Document Loaders",
        "description": "Load data from PDF files",
        "inputParams": [
          {
            "label": "Pdf File",
            "name": "pdfFile",
            "type": "file",
            "fileType": ".pdf",
            "id": "pdfFile_0-input-pdfFile-file",
            "display": true
          },
          {
            "label": "Usage",
            "name": "usage",
            "type": "options",
            "options": [
              {
                "label": "One document per page",
                "name": "perPage"
              },
              {
                "label": "One document per file",
                "name": "perFile"
              }
            ],
            "default": "perPage",
            "id": "pdfFile_0-input-usage-options",
            "display": true
          },
          {
            "label": "Use Legacy Build",
            "name": "legacyBuild",
            "type": "boolean",
            "optional": true,
            "additionalParams": true,
            "id": "pdfFile_0-input-legacyBuild-boolean",
            "display": true
          },
          {
            "label": "Additional Metadata",
            "name": "metadata",
            "type": "json",
            "description": "Additional metadata to be added to the extracted documents",
            "optional": true,
            "additionalParams": true,
            "id": "pdfFile_0-input-metadata-json",
            "display": true
          },
          {
            "label": "Omit Metadata Keys",
            "name": "omitMetadataKeys",
            "type": "string",
            "rows": 4,
            "description": "Each document loader comes with a default set of metadata keys that are extracted from the document. You can use this field to omit some of the default metadata keys. The value should be a list of keys, seperated by comma. Use * to omit all metadata keys execept the ones you specify in the Additional Metadata field",
            "placeholder": "key1, key2, key3.nestedKey1",
            "optional": true,
            "additionalParams": true,
            "id": "pdfFile_0-input-omitMetadataKeys-string",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Text Splitter",
            "name": "textSplitter",
            "type": "TextSplitter",
            "optional": true,
            "id": "pdfFile_0-input-textSplitter-TextSplitter",
            "display": true
          }
        ],
        "inputs": {
          "textSplitter": "{{recursiveCharacterTextSplitter_0.data.instance}}",
          "usage": "perFile",
          "legacyBuild": "",
          "metadata": "",
          "omitMetadataKeys": ""
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "Array of document objects containing metadata and pageContent",
            "options": [
              {
                "id": "pdfFile_0-output-document-Document|json",
                "name": "document",
                "label": "Document",
                "description": "Array of document objects containing metadata and pageContent",
                "type": "Document | json"
              },
              {
                "id": "pdfFile_0-output-text-string|json",
                "name": "text",
                "label": "Text",
                "description": "Concatenated string from pageContent of documents",
                "type": "string | json"
              }
            ],
            "default": "document"
          }
        ],
        "outputs": {
          "output": "document"
        },
        "selected": false
      },
      "width": 300,
      "height": 560,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 1650,
        "y": -450
      }
    },
    {
      "id": "recursiveCharacterTextSplitter_0",
      "position": {
        "x": 1275,
        "y": -450
      },
      "type": "customNode",
      "data": {
        "id": "recursiveCharacterTextSplitter_0",
        "label": "Recursive Character Text Splitter",
        "version": 2,
        "name": "recursiveCharacterTextSplitter",
        "type": "RecursiveCharacterTextSplitter",
        "baseClasses": [
          "RecursiveCharacterTextSplitter",
          "TextSplitter",
          "BaseDocumentTransformer",
          "Runnable"
        ],
        "category": "Text Splitters",
        "description": "Split documents recursively by different characters - starting with \"\\n\\n\", then \"\\n\", then \" \"",
        "inputParams": [
          {
            "label": "Chunk Size",
            "name": "chunkSize",
            "type": "number",
            "description": "Number of characters in each chunk. Default is 1000.",
            "default": 1000,
            "optional": true,
            "id": "recursiveCharacterTextSplitter_0-input-chunkSize-number",
            "display": true
          },
          {
            "label": "Chunk Overlap",
            "name": "chunkOverlap",
            "type": "number",
            "description": "Number of characters to overlap between chunks. Default is 200.",
            "default": 200,
            "optional": true,
            "id": "recursiveCharacterTextSplitter_0-input-chunkOverlap-number",
            "display": true
          },
          {
            "label": "Custom Separators",
            "name": "separators",
            "type": "string",
            "rows": 4,
            "description": "Array of custom separators to determine when to split the text, will override the default separators",
            "placeholder": "[\"|\", \"##\", \">\", \"-\"]",
            "additionalParams": true,
            "optional": true,
            "id": "recursiveCharacterTextSplitter_0-input-separators-string",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "chunkSize": 1000,
          "chunkOverlap": 200,
          "separators": ""
        },
        "outputAnchors": [
          {
            "id": "recursiveCharacterTextSplitter_0-output-recursiveCharacterTextSplitter-RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
            "name": "recursiveCharacterTextSplitter",
            "label": "RecursiveCharacterTextSplitter",
            "description": "Split documents recursively by different characters - starting with \"\\n\\n\", then \"\\n\", then \" \"",
            "type": "RecursiveCharacterTextSplitter | TextSplitter | BaseDocumentTransformer | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 436,
      "selected": false,
      "positionAbsolute": {
        "x": 1275,
        "y": -450
      },
      "dragging": false
    },
    {
      "id": "memoryVectorStore_0",
      "position": {
        "x": 2075,
        "y": -75
      },
      "type": "customNode",
      "data": {
        "id": "memoryVectorStore_0",
        "label": "In-Memory Vector Store",
        "version": 1,
        "name": "memoryVectorStore",
        "type": "Memory",
        "baseClasses": [
          "Memory",
          "VectorStoreRetriever",
          "BaseRetriever"
        ],
        "category": "Vector Stores",
        "description": "In-memory vectorstore that stores embeddings and does an exact, linear search for the most similar embeddings.",
        "inputParams": [
          {
            "label": "Top K",
            "name": "topK",
            "description": "Number of top results to fetch. Default to 4",
            "placeholder": "4",
            "type": "number",
            "optional": true,
            "id": "memoryVectorStore_0-input-topK-number",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Document",
            "name": "document",
            "type": "Document",
            "list": true,
            "optional": true,
            "id": "memoryVectorStore_0-input-document-Document",
            "display": true
          },
          {
            "label": "Embeddings",
            "name": "embeddings",
            "type": "Embeddings",
            "id": "memoryVectorStore_0-input-embeddings-Embeddings",
            "display": true
          }
        ],
        "inputs": {
          "document": [
            "{{pdfFile_0.data.instance}}"
          ],
          "embeddings": "{{openAIEmbeddingsCustom_0.data.instance}}",
          "topK": ""
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "memoryVectorStore_0-output-retriever-Memory|VectorStoreRetriever|BaseRetriever",
                "name": "retriever",
                "label": "Memory Retriever",
                "description": "",
                "type": "Memory | VectorStoreRetriever | BaseRetriever"
              },
              {
                "id": "memoryVectorStore_0-output-vectorStore-Memory|VectorStore",
                "name": "vectorStore",
                "label": "Memory Vector Store",
                "description": "",
                "type": "Memory | VectorStore"
              }
            ],
            "default": "retriever"
          }
        ],
        "outputs": {
          "output": "retriever"
        },
        "selected": false
      },
      "width": 300,
      "height": 413,
      "selected": false,
      "positionAbsolute": {
        "x": 2075,
        "y": -75
      },
      "dragging": false
    },
    {
      "id": "conversationalRetrievalQAChain_0",
      "position": {
        "x": 2600,
        "y": -250
      },
      "type": "customNode",
      "data": {
        "id": "conversationalRetrievalQAChain_0",
        "label": "Conversational Retrieval QA Chain",
        "version": 3,
        "name": "conversationalRetrievalQAChain",
        "type": "ConversationalRetrievalQAChain",
        "baseClasses": [
          "ConversationalRetrievalQAChain",
          "BaseChain",
          "Runnable"
        ],
        "category": "Chains",
        "description": "Document QA - built on RetrievalQAChain to provide a chat history component",
        "inputParams": [
          {
            "label": "Return Source Documents",
            "name": "returnSourceDocuments",
            "type": "boolean",
            "optional": true,
            "id": "conversationalRetrievalQAChain_0-input-returnSourceDocuments-boolean",
            "display": true
          },
          {
            "label": "Rephrase Prompt",
            "name": "rephrasePrompt",
            "type": "string",
            "description": "Using previous chat history, rephrase question into a standalone question",
            "warning": "Prompt must include input variables: {chat_history} and {question}",
            "rows": 4,
            "additionalParams": true,
            "optional": true,
            "default": "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n\nChat History:\n{chat_history}\nFollow Up Input: {question}\nStandalone Question:",
            "id": "conversationalRetrievalQAChain_0-input-rephrasePrompt-string",
            "display": true
          },
          {
            "label": "Response Prompt",
            "name": "responsePrompt",
            "type": "string",
            "description": "Taking the rephrased question, search for answer from the provided context",
            "warning": "Prompt must include input variable: {context}",
            "rows": 4,
            "additionalParams": true,
            "optional": true,
            "default": "I want you to act as a document that I am having a conversation with. Your name is \"AI Assistant\". Using the provided context, answer the user's question to the best of your ability using the resources provided.\nIf there is nothing in the context relevant to the question at hand, just say \"Hmm, I'm not sure\" and stop after that. Refuse to answer any question not about the info. Never break character.\n------------\n{context}\n------------\nREMEMBER: If there is no relevant information within the context, just say \"Hmm, I'm not sure\". Don't try to make up an answer. Never break character.",
            "id": "conversationalRetrievalQAChain_0-input-responsePrompt-string",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "id": "conversationalRetrievalQAChain_0-input-model-BaseChatModel",
            "display": true
          },
          {
            "label": "Vector Store Retriever",
            "name": "vectorStoreRetriever",
            "type": "BaseRetriever",
            "id": "conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever",
            "display": true
          },
          {
            "label": "Memory",
            "name": "memory",
            "type": "BaseMemory",
            "optional": true,
            "description": "If left empty, a default BufferMemory will be used",
            "id": "conversationalRetrievalQAChain_0-input-memory-BaseMemory",
            "display": true
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "conversationalRetrievalQAChain_0-input-inputModeration-Moderation",
            "display": true
          }
        ],
        "inputs": {
          "model": "{{chatNvidiaNIM_0.data.instance}}",
          "vectorStoreRetriever": "{{memoryVectorStore_0.data.instance}}",
          "memory": "{{bufferMemory_0.data.instance}}",
          "returnSourceDocuments": false,
          "rephrasePrompt": "A≈üaƒüƒ±daki sohbet ge√ßmi≈üini ve yeni soruyu birle≈ütirerek, tek ba≈üƒ±na anla≈üƒ±lƒ±r bir soru c√ºmlesi olu≈ütur.\n\nGe√ßmi≈ü: {chat_history}\nSoru: {question}\nBaƒüƒ±msƒ±z Soru:",
          "responsePrompt": "SEN T√úRKƒ∞YE SAƒûLIK Sƒ∞STEMƒ∞NE (MHRS/SUT) HAKƒ∞M, TRƒ∞YAJ VE Y√ñNLENDƒ∞RME UZMANISIN.\n\nG√ñREVƒ∞N:\nKullanƒ±cƒ±nƒ±n ≈üikayetini ve demografik bilgilerini analiz et. A≈üaƒüƒ±daki \"KARAR ALGORƒ∞TMASI\"nƒ± sƒ±rasƒ±yla uygula.\n\n‚ö†Ô∏è √ñNEMLƒ∞ KURALLAR:\n1. Bƒ∞LGƒ∞ KAYNAƒûI: √ñncelikle sana verilen \"Baƒülam\" (Context) verisini kullan. Eƒüer semptom baƒülamda yoksa, genel tƒ±bbi bilgini MHRS/Poliklinik standartlarƒ±na g√∂re kullan.\n2. ANTƒ∞-TEDAVƒ∞: ASLA ila√ß ismi veya tedavi tavsiyesi verme.\n3. FORMAT: Cevabƒ± her zaman Markdown formatƒ±nda ver.\n\nGƒ∞RDƒ∞LER:\n- Baƒülam: {context}\n- Soru: {question}\n\n---\n### üö® KARAR ALGORƒ∞TMASI üö®\n\nADIM 1: KIRMIZI ALAN (ACƒ∞L) KONTROL√ú\n≈ûunlar varsa hemen \"RED\" ver: \"Bayƒ±lma\", \"Nefes darlƒ±ƒüƒ±\", \"G√∂ƒü√ºs aƒürƒ±sƒ±\" (40+ ya≈ü), \"Dayanƒ±lmaz karƒ±n aƒürƒ±sƒ±\", \"ƒ∞ntihar fikri\", \"Durdurulamayan kanama\".\n\nADIM 2: YA≈û Fƒ∞LTRESƒ∞ (PEDƒ∞ATRƒ∞)\nEƒüer ya≈ü < 18 ise, √∂nerilen bran≈üƒ±n ba≈üƒ±na mutlaka \"√áOCUK\" ekle.\n\nADIM 3: BRAN≈û SE√áƒ∞Mƒ∞\n- Baƒülamda ara. Yoksa genel bilgiye bak.\n- Testis/ƒ∞drar -> √úroloji.\n- Meme/Fƒ±tƒ±k -> Genel Cerrahi.\n- Kƒ±rƒ±k/√áƒ±kƒ±k -> Ortopedi.\n\nADIM 4: YE≈ûƒ∞L Lƒ∞STE KONTROL√ú\n- Endokrin, Romatoloji vb. isteniyorsa ve hasta takipli deƒüilse -> DAHƒ∞Lƒ∞YE'ye y√∂nlendir.\n\n---\n### √áIKTI FORMATI:\n\n# üè• √ñNERƒ∞LEN B√ñL√úM: [B√∂l√ºm Adƒ±]\n\n### üìã A√ßƒ±klama:\n[Neden bu b√∂l√ºm√º se√ßtiƒüini, baƒülama veya genel tƒ±bbi bilgiye dayanarak",
          "inputModeration": ""
        },
        "outputAnchors": [
          {
            "id": "conversationalRetrievalQAChain_0-output-conversationalRetrievalQAChain-ConversationalRetrievalQAChain|BaseChain|Runnable",
            "name": "conversationalRetrievalQAChain",
            "label": "ConversationalRetrievalQAChain",
            "description": "Document QA - built on RetrievalQAChain to provide a chat history component",
            "type": "ConversationalRetrievalQAChain | BaseChain | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 538,
      "selected": false,
      "positionAbsolute": {
        "x": 2600,
        "y": -250
      },
      "dragging": false
    },
    {
      "id": "openAIEmbeddingsCustom_0",
      "position": {
        "x": 1650,
        "y": 125
      },
      "type": "customNode",
      "data": {
        "id": "openAIEmbeddingsCustom_0",
        "label": "OpenAI Embeddings Custom",
        "version": 3,
        "name": "openAIEmbeddingsCustom",
        "type": "OpenAIEmbeddingsCustom",
        "baseClasses": [
          "OpenAIEmbeddingsCustom",
          "Embeddings"
        ],
        "category": "Embeddings",
        "description": "OpenAI API to generate embeddings for a given text",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "openAIEmbeddingsCustom_0-input-credential-credential",
            "display": true
          },
          {
            "label": "Strip New Lines",
            "name": "stripNewLines",
            "type": "boolean",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddingsCustom_0-input-stripNewLines-boolean",
            "display": true
          },
          {
            "label": "Batch Size",
            "name": "batchSize",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddingsCustom_0-input-batchSize-number",
            "display": true
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddingsCustom_0-input-timeout-number",
            "display": true
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddingsCustom_0-input-basepath-string",
            "display": true
          },
          {
            "label": "BaseOptions",
            "name": "baseOptions",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddingsCustom_0-input-baseOptions-json",
            "display": true
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "string",
            "optional": true,
            "id": "openAIEmbeddingsCustom_0-input-modelName-string",
            "display": true
          },
          {
            "label": "Dimensions",
            "name": "dimensions",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddingsCustom_0-input-dimensions-number",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "stripNewLines": false,
          "batchSize": "",
          "timeout": "",
          "basepath": "https://integrate.api.nvidia.com/v1",
          "baseOptions": "",
          "modelName": "nvidia/nv-embed-v1",
          "dimensions": ""
        },
        "outputAnchors": [
          {
            "id": "openAIEmbeddingsCustom_0-output-openAIEmbeddingsCustom-OpenAIEmbeddingsCustom|Embeddings",
            "name": "openAIEmbeddingsCustom",
            "label": "OpenAIEmbeddingsCustom",
            "description": "OpenAI API to generate embeddings for a given text",
            "type": "OpenAIEmbeddingsCustom | Embeddings"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 433,
      "selected": false,
      "positionAbsolute": {
        "x": 1650,
        "y": 125
      },
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "openAIEmbeddingsCustom_0",
      "sourceHandle": "openAIEmbeddingsCustom_0-output-openAIEmbeddingsCustom-OpenAIEmbeddingsCustom|Embeddings",
      "target": "memoryVectorStore_0",
      "targetHandle": "memoryVectorStore_0-input-embeddings-Embeddings",
      "type": "buttonedge",
      "id": "openAIEmbeddingsCustom_0-openAIEmbeddingsCustom_0-output-openAIEmbeddingsCustom-OpenAIEmbeddingsCustom|Embeddings-memoryVectorStore_0-memoryVectorStore_0-input-embeddings-Embeddings"
    },
    {
      "source": "recursiveCharacterTextSplitter_0",
      "sourceHandle": "recursiveCharacterTextSplitter_0-output-recursiveCharacterTextSplitter-RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
      "target": "pdfFile_0",
      "targetHandle": "pdfFile_0-input-textSplitter-TextSplitter",
      "type": "buttonedge",
      "id": "recursiveCharacterTextSplitter_0-recursiveCharacterTextSplitter_0-output-recursiveCharacterTextSplitter-RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable-pdfFile_0-pdfFile_0-input-textSplitter-TextSplitter"
    },
    {
      "source": "pdfFile_0",
      "sourceHandle": "pdfFile_0-output-document-Document|json",
      "target": "memoryVectorStore_0",
      "targetHandle": "memoryVectorStore_0-input-document-Document",
      "type": "buttonedge",
      "id": "pdfFile_0-pdfFile_0-output-document-Document|json-memoryVectorStore_0-memoryVectorStore_0-input-document-Document"
    },
    {
      "source": "memoryVectorStore_0",
      "sourceHandle": "memoryVectorStore_0-output-retriever-Memory|VectorStoreRetriever|BaseRetriever",
      "target": "conversationalRetrievalQAChain_0",
      "targetHandle": "conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever",
      "type": "buttonedge",
      "id": "memoryVectorStore_0-memoryVectorStore_0-output-retriever-Memory|VectorStoreRetriever|BaseRetriever-conversationalRetrievalQAChain_0-conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever"
    },
    {
      "source": "chatNvidiaNIM_0",
      "sourceHandle": "chatNvidiaNIM_0-output-chatNvidiaNIM-ChatNvidiaNIM|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "conversationalRetrievalQAChain_0",
      "targetHandle": "conversationalRetrievalQAChain_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatNvidiaNIM_0-chatNvidiaNIM_0-output-chatNvidiaNIM-ChatNvidiaNIM|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-conversationalRetrievalQAChain_0-conversationalRetrievalQAChain_0-input-model-BaseChatModel"
    },
    {
      "source": "bufferMemory_0",
      "sourceHandle": "bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory",
      "target": "conversationalRetrievalQAChain_0",
      "targetHandle": "conversationalRetrievalQAChain_0-input-memory-BaseMemory",
      "type": "buttonedge",
      "id": "bufferMemory_0-bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory-conversationalRetrievalQAChain_0-conversationalRetrievalQAChain_0-input-memory-BaseMemory"
    }
  ]
}